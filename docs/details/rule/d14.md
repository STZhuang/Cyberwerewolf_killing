## D14 · 灰度、模型 A/B 与排行榜

### 1. 目标

建立一套支持**LLM 模型灰度发布、A/B 实验和性能排行榜**的机制。该机制旨在通过数据驱动的方式，科学地评估不同模型（或不同 Prompt 策略）在真实游戏环境中的表现，从而持续优化 Agent 的智力、合规性和成本效益。

### 2. 灰度与 A/B 实验设计

#### 2.1 实验单元与分流

*   **实验单元**: A/B 实验的核心是**模型绑定 (Binding)**（参见 D01）。我们可以将不同的模型 `Preset` 绑定到不同的实验组。
*   **分流逻辑**:
    *   **按房间分流**: 最简单的分流方式。通过对 `roomId` 进行哈希，将整个房间的 Agent（或特定角色的 Agent）分配到不同的实验组。
        *   *示例*: `hash(roomId) % 100 < 10` 的房间进入实验组 A (使用 `gpt-4o`)，其余进入对照组 B (使用 `gpt-4o-mini`)。
    *   **按角色/席位分流**: 在同一个房间内，为不同角色或席位的 Agent 分配不同的模型。这可以用于测试不同角色与模型的适配性。
    *   **按规则分流**: 支持更复杂的规则，如按玩家段位、时间段、对局类型等进行分流。

#### 2.2 实验元数据

*   为了追踪和分析，每次对局的 `games` 表中都应记录其所属的实验标签。
    ```json
    // games.config
    {
      "experiment": {
        "id": "exp-wolf-model-comparison-q3",
        "variant": "A" // "A" for gpt-4o, "B" for claude-3-opus
      }
    }
    ```

### 3. 核心评估指标 (Metrics)

评估一个模型的好坏，需要从多个维度进行考量。

| 维度       | 指标名称                               | 描述与计算方式                                               |
| ---------- | -------------------------------------- | ------------------------------------------------------------ |
| **游戏表现** | `win_rate` (胜率)                      | 按模型/角色/阵营聚合的胜率。                                 |
|            | `avg_survival_rounds` (平均存活轮次)   | 该模型控制的 Agent 平均能存活多少个游戏回合。                |
|            | `key_role_find_rate` (关键角色发现率)  | 对于预言家等神牌，查验并找出狼人的准确率。                   |
| **合规性**   | `tool_legality_rate` (工具合法率)      | 调用工具的合法率，是衡量模型理解规则能力的核心指标。         |
|            | `violation_rate` (越权/违规率)         | 发言中出现泄露身份、辱骂等违规内容的比例。                   |
|            | `gm_rejection_rate` (GM 拒绝率)        | 被 GM Agent 判定为不合规并拒绝的行动比例。                   |
| **成本效益** | `avg_tokens_per_game` (每局平均 Token) | 一局游戏中，该模型平均消耗的总 Token 数。                    |
|            | `cost_per_win` (每胜局成本)            | `avg_cost_per_game / win_rate`，衡量成本效益。               |
| **稳定性**   | `api_failure_rate` (API 失败率)        | 调用该模型底层 API 的失败率。                                |
|            | `p95_latency_ms` (P95 延迟)            | 模型响应时长的 P95 百分位。                                  |

### 4. 数据报表与排行榜

*   **数据聚合**: 后端需要一个定时任务（如每日执行），从 `games`, `events`, `agent_sessions` 等表中聚合数据，计算出上述指标，并存入专门的分析结果表。
    *   `model_stats_daily (date, model_id, experiment_id, variant, win_rate, legality_rate, avg_cost, ...)`
*   **排行榜 API**:
    *   `GET /analytics/leaderboard?metric=win_rate&role=Werewolf`: 获取狼人角色的模型胜率排行榜。
*   **可视化看板**:
    *   **A/B 实验看板**: 并排展示实验组与对照组在各项核心指标上的对比（带置信区间）。
    *   **模型综合排行榜**: 创建一个综合评分 `score`（例如，`score = w1*win_rate + w2*legality_rate - w3*cost`），并按此分数对所有模型进行排名。

### 5. 验收标准

*   **端到端流程**: 能够完整地执行一次 A/B 实验：
    1.  通过 Admin 界面配置实验分流规则。
    2.  在新生成的对局中，`games.config` 被正确打上实验标签。
    3.  对局结束后，数据能够被聚合脚本正确处理。
    4.  在分析看板上，能够清晰地看到实验组与对照组的数据对比。
*   **统计有效性**: 对于胜率等关键指标，报表中应包含样本量 (`sample_size`) 和置信区间，以避免根据少量数据得出错误结论。
*   **灵活性**: 系统应支持在不修改代码的情况下，通过配置来开启、关闭和调整 A/B 实验。